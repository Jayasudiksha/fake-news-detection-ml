{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2r7QIj6i8KB4wD434LQe+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCnAQ_HgngNm",
        "outputId": "a2fc2af5-acd9-443c-e3a7-0271ab6c6c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas scikit-learn nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "fake = pd.read_csv('Fake.csv')\n",
        "real = pd.read_csv('True.csv')\n",
        "\n",
        "# Add a label column: 0 = fake, 1 = real\n",
        "fake['label'] = 0\n",
        "real['label'] = 1\n",
        "\n",
        "# Combine the datasets\n",
        "data = pd.concat([fake, real], axis=0)\n",
        "\n",
        "# Shuffle the dataset\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Quick look\n",
        "print(data.head())\n",
        "print(data['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOQBedsRnmtJ",
        "outputId": "b065394e-1f7c-4dac-8678-70b556d80f04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                               title  \\\n",
            "0   BREAKING: Israel‚Äôs ‚ÄúWorst Fears Confirmed,‚Äù S...   \n",
            "1  U.N. offers to help resolve Baghdad, Kurdistan...   \n",
            "2  Trump Transition: As Secretary of State, Tulsi...   \n",
            "3  UNIVERSITY PRESIDENT APOLOGIZES TO TRAUMATIZED...   \n",
            "4  ERIC HOLDER Encourages DOJ To Keep Attacking T...   \n",
            "\n",
            "                                                text    subject  \\\n",
            "0  In a bombshell revelation, The New York Times ...       News   \n",
            "1  BAGHDAD (Reuters) - The United Nations has off...  worldnews   \n",
            "2  Patrick Henningsen 21st Century WireSo far as ...    US_News   \n",
            "3  ***WARNING***If you are between the ages of 18...  left-news   \n",
            "4  The most corrupt Attorney General in the histo...  left-news   \n",
            "\n",
            "                  date  label  \n",
            "0         May 16, 2017      0  \n",
            "1  September 28, 2017       1  \n",
            "2    November 23, 2016      0  \n",
            "3         Jul 18, 2016      0  \n",
            "4          Jul 1, 2017      0  \n",
            "label\n",
            "0    23481\n",
            "1    21417\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    # Tokenize and remove stopwords + lemmatize\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply to your dataset\n",
        "data['processed_text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "print(data['processed_text'].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUF7-v1onpXe",
        "outputId": "907d42fb-8719-412c-f4ba-d7d6ab12e656"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    bombshell revelation new york time named israe...\n",
            "1    baghdad reuters united nation offered help sol...\n",
            "2    patrick henningsen 21st century wireso far wor...\n",
            "3    warningif age 1823 believe everything leftist ...\n",
            "4    corrupt attorney general history united state ...\n",
            "Name: processed_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Create the vectorizer\n",
        "vectorizer = TfidfVectorizer(max_df=0.7)\n",
        "\n",
        "# Fit and transform the text\n",
        "X = vectorizer.fit_transform(data['processed_text'])\n",
        "\n",
        "# Labels\n",
        "y = data['label']"
      ],
      "metadata": {
        "id": "VEphfm4BntMT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train size:\", X_train.shape)\n",
        "print(\"Test size:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW8zQH7tnxWp",
        "outputId": "1f73639f-261b-4d2e-bac8-31fe558d786b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: (35918, 219464)\n",
            "Test size: (8980, 219464)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU0FRZrAn0h_",
        "outputId": "e0e7792c-fdd4-4085-bcc9-cade626e2990"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9864142538975501\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      4675\n",
            "           1       0.99      0.99      0.99      4305\n",
            "\n",
            "    accuracy                           0.99      8980\n",
            "   macro avg       0.99      0.99      0.99      8980\n",
            "weighted avg       0.99      0.99      0.99      8980\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[4611   64]\n",
            " [  58 4247]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter your own news text here\n",
        "input_news = \"Breaking: Government announces new economic policy to support farmers.\"\n",
        "\n",
        "# Preprocess the input\n",
        "processed_input = preprocess_text(input_news)\n",
        "\n",
        "# Vectorize the input using the same TF-IDF vectorizer\n",
        "vectorized_input = vectorizer.transform([processed_input])\n",
        "\n",
        "# Predict using the trained model\n",
        "prediction = model.predict(vectorized_input)[0]\n",
        "\n",
        "# Show result\n",
        "result = \"üü¢ Real News\" if prediction == 1 else \"üî¥ Fake News\"\n",
        "print(\"Prediction:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPwzM_QLn3I7",
        "outputId": "d154b85c-7c97-41f5-f42b-140a867f7d06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: üî¥ Fake News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_news = input(\"Enter a news article or headline: \")\n",
        "\n",
        "processed_input = preprocess_text(input_news)\n",
        "vectorized_input = vectorizer.transform([processed_input])\n",
        "prediction = model.predict(vectorized_input)[0]\n",
        "result = \"üü¢ Real News\" if prediction == 1 else \"üî¥ Fake News\"\n",
        "print(\"Prediction:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXtl8oD5n62n",
        "outputId": "26cc89b2-d224-4297-d94e-3e864ec142be"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a news article or headline: NASA announces water on mars\n",
            "Prediction: üî¥ Fake News\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save model and vectorizer\n",
        "pickle.dump(model, open('fake_news_model.pkl', 'wb'))\n",
        "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "uS4vw_hSn9lx"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}